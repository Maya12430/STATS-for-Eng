# -*- coding: utf-8 -*-
"""Maya Lev Lehman Lab 10.1 Linear Auto Gen.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bKptVyqh5PMVXVkyFnuUjpMtwSWTtck0

## Setup

### Imports
"""

import numpy as np #for numerical operations
import matplotlib.pyplot as plt #to generate plots
import urllib.request #for handling url requests
from PIL import Image #for image processing
from imageio import * #for reading and writing a wide range of image data
import torch #for machine learning tasks
from skimage.transform import resize #for image resize
from mpl_toolkits.axes_grid1.axes_rgb import make_rgb_axes, RGBAxes #for RGB image visualization
from torchvision.models import * #for pre-trained models
from torchvision.datasets import MNIST,KMNIST,FashionMNIST #for popular datasets like MNIST, KMNIST, FahsionMNIST
from skimage.util import montage #to create a collage from a set of images

!pip install wandb #install weight and bias lib
import wandb as wb

def plot(x): #define a plot function
    if type(x) == torch.Tensor :
        x = x.cpu().detach().numpy() #convert tensor to an np array after it moves it to CPU, then detach from the graph

    fig, ax = plt.subplots() #to create figures and subplots
    im = ax.imshow(x, cmap = 'gray')
    ax.axis('off') #turn axis off
    fig.set_size_inches(5, 5) #set figure size to 5x5
    plt.show()

def montage_plot(x):
    x = np.pad(x, pad_width=((0, 0), (1, 1), (1, 1)), mode='constant', constant_values=0) #to pad the input array on 2nd and 3rd dim
    plot(montage(x)) #montage of padded array

b = 1000 #batch size

def get_batch(mode):
    if mode == "train": #fetch a batch of data (train)
        r = np.random.randint(X.shape[0]-b)
        x = X[r:r+b,:]
        y = Y[r:r+b]
    elif mode == "test": #fetch a batch of data (test)
        r = np.random.randint(X_test.shape[0]-b) #random starting index for test data
        x = X_test[r:r+b,:] #slice the test data and labels for the batch
        y = Y_test[r:r+b]
    return x,y

"""## MNIST

### Load Data
"""

# #MNIST
train_set = MNIST('./data', train=True, download=True)
test_set  = MNIST('./data', train=False, download=True)

#KMNIST
# train_set = KMNIST('./data', train=True, download=True)
# test_set =  KMNIST('./data', train=False, download=True)

# Fashion MNIST
# train_set = FashionMNIST('./data', train=True, download=True)
# test_set =  FashionMNIST('./data', train=False, download=True)

X = train_set.data.numpy() #to convert train set images to numpy arrays
X_test = test_set.data.numpy() #convert the test set images to " "
Y = train_set.targets.numpy() #convert train set labels to " "
Y_test = test_set.targets.numpy() #convert test set labels to " "

X = X[:,None,:,:]/255 #adding a channel dim to the train set and normalize it
X_test = X_test[:,None,:,:]/255 #adding a channel dim to the test set and normalize it

X.shape #print X shape

Y[50000] #label of image 50001

plot(X[50000,0,:,:]) #50001 image for the dataset

Y[100] #label image 101

X.shape

X[0:25,0,:,:].shape #shape of the first 25 images in 28x28

montage_plot(X[125:150,0,:,:]) #from index 125 to 149

X.shape[0] # number of training images

X_test.shape

X.shape[0]

X_test.shape[0] #number of test images

def GPU(data): #define a function to convert data to CUDA tensor for GPU processing, with grad tracking
    return torch.tensor(data, requires_grad=True, dtype=torch.float, device=torch.device('cuda'))

def GPU_data(data):#define a function to convert data to CUDA tensor for GPU processing, without grad tracking
    return torch.tensor(data, requires_grad=False, dtype=torch.float, device=torch.device('cuda'))

X = GPU_data(X) #transfer train images
Y = GPU_data(Y) #transfer train labels
X_test = GPU_data(X_test) #transfer test images
Y_test = GPU_data(Y_test) #transfer test labels

X = X.reshape(X.shape[0],784) #reshape train images
X_test = X_test.reshape(X_test.shape[0],784) #reshape test images

X.shape #shape of X

"""
### Classifier
"""

x,y = get_batch('train') #retreive batch containing the training data

x.shape #shape of the tensor

plot(x[0].reshape(28,28)) #first image

plot(x[1].reshape(28,28)) #second image

plot(x[2].reshape(28,28)) #3rd image

y[:10] # print labels of the first ten images from the dataset

W = GPU(np.random.randn(784,10))



x.shape, W.shape

torch.matmul(x,W).shape

(x@W).shape

# Commented out IPython magic to ensure Python compatibility.
# %%timeit
# x@W

x@W

y2 = x@W

plot(y2[:50])

y

y.shape

def one_hot(y):
    y2 = GPU_data(torch.zeros((y.shape[0],10))) #encoded tensor with zeros based on the length of y and number of classes
    for i in range(y.shape[0]):
        y2[i,int(y[i])] = 1 #set the appropriate index for each smaple to 1 for one=hot encoding
    return y2 #return the one-hot encoded tensor

one_hot(y)

torch.argmax(y2,1)

torch.sum(y == torch.argmax(y2,1))/b

X.shape

X@W

torch.argmax(X@W,1)

Y

torch.sum(torch.argmax(X@W,1) == Y)/60000

X@W

W.shape

W[:,0].shape

plot(W[:,0].reshape(28,28))

plot(W[:,2].reshape(28,28))

W.shape

(W.T).shape

montage_plot((W.T).reshape(10,28,28).cpu().detach().numpy())

def softmax(x): #define a softmax function
    s1 = torch.exp(x - torch.max(x,1)[0][:,None]) #apply the function to the input tensor
    s = s1 / s1.sum(1)[:,None]
    return s

def cross_entropy(outputs, labels): #define a cross-entropy function
    return -torch.sum(softmax(outputs).log()[range(outputs.size()[0]), labels.long()])/outputs.size()[0] #compute its loss from the models' outputs and true labels

def acc(out,y): #define accuracy function
    #compare predicted class with true labels to find accuracy
    return (torch.sum(torch.max(out,1)[1] == y).item())/y.shape[0]

def get_batch(mode):
    b = c.b #batch size from external vairbale c.b
    if mode == "train":
        r = np.random.randint(X.shape[0]-b) #random batch of data for the train set
        x = X[r:r+b,:] #data batch
        y = Y[r:r+b] #label batch
    elif mode == "test":
        r = np.random.randint(X_test.shape[0]-b) #random batch of data from the test set
        x = X_test[r:r+b,:] #data batch
        y = Y_test[r:r+b] #label batch
    return x,y

def model(x,w): #model prediction function

    return x@w[0] #matrix mult. of x and w (input and weight)

def gradient_step(w):

    w[0].data = w[0].data - c.L*w[0].grad.data #adjusting weights with the learning rate and gradient

    w[0].grad.data.zero_() #reset gradients for zero for the next update

def make_plots():

    acc_train = acc(model(x,w),y) #train accuracy

    xt,yt = get_batch('test')

    acc_test = acc(model(xt,w),yt) #test accuracy

    wb.log({"acc_train": acc_train, "acc_test": acc_test}) #log accuracy

def Truncated_Normal(size):

    u1 = torch.rand(size)*(1-np.exp(-2)) + np.exp(-2) #unifrom dist. adjustment
    u2 = torch.rand(size) #uniform dist. sample
    z  = torch.sqrt(-2*torch.log(u1)) * torch.cos(2*np.pi*u2) #Box Muller transform

    return z

for run in range(3):

    wb.init(project="Simple_Linear_SGD_123");
    c = wb.config

    c.L = 0.1 #learning rate
    c.b = 1024 #batch size
    c.epochs = 10000 #number of epochs from the Weight and biases configuration

    w = [GPU(Truncated_Normal((784,10)))]

    for i in range(c.epochs):

        x,y = get_batch('train') #batch of the train set

        out = model(x,w) #predictions for the current batch

        loss = cross_entropy(softmax(out),y) #cross-entropy loss

        loss.backward() #to calcualte gradients

        gradient_step(w) #update model's weights

        make_plots() #for tracking

        if (i+1) % 10000 == 0: montage_plot((w[0].T).reshape(10,28,28).cpu().detach().numpy())

for run in range(100):

    wb.init(project="Simple_Linear_Adam_2");
    c = wb.config

    c.L = 0.01 #learning rate
    c.b = 1024 #batch size
    c.epochs = 100000 #number of epochs

    w = [GPU(Truncated_Normal((784,10)))] #model weights with truncates normal dist., move to GPU

    optimizer = torch.optim.Adam(w, lr=c.L) #with the weights and learning rate

    for i in range(c.epochs):

        x,y = get_batch('train')#get batch train set

        loss = cross_entropy(softmax(model(x,w)),y)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        wb.log({"loss": loss}) #log the loss value to w&b

        make_plots()
#every 10,000 epochs, visualize the model w
        if i % 10000 == 0 : montage_plot((w[0].T).reshape(10,28,28).cpu().detach().numpy())

"""
### Autoencoder
"""

def get_batch(mode):
    b = 1024
    if mode == "train":
        r = np.random.randint(X.shape[0]-b)
        x = X[r:r+b,:]
        y = Y[r:r+b]
    elif mode == "test":
        r = np.random.randint(X_test.shape[0]-b)
        x = X_test[r:r+b,:]
        y = Y_test[r:r+b]
    return x,y

X = X.reshape(X.shape[0],1,28,28)
X_test = X_test.reshape(X_test.shape[0],1,28,28)

#import pytorch and functional API for neural network layers
import torchvision
from torch.nn.functional import *

X = torchvision.transforms.functional.normalize(X,0.5,0.5)
X_test = torchvision.transforms.functional.normalize(X_test,0.5,0.5)

def Encoder(x,w):
    x = relu(conv2d(x,w[0], stride=(2, 2), padding=(1, 1))) #convolution and ReLu actiavtion
    x = relu(conv2d(x,w[1], stride=(2, 2), padding=(1, 1))) #convolution and ReLU
    x = x.view(x.size(0), 6272) #to flatten the feuature maps
    x = linear(x,w[2]) #linear transformation
    return x

def Decoder(x,w):
    x = linear(x,w[3]) #linear transformation
    x = x.view(x.size(0), 128, 7, 7) #reshape to expected size ofr deconvolution
    x = relu(conv_transpose2d(x,w[4], stride=(2, 2), padding=(1, 1))) #deconvo and ReLU
    x = torch.tanh(conv_transpose2d(x,w[5], stride=(2, 2), padding=(1, 1)))#final deconvo and tanh activation
    return x

def Autoencoder(x,w): #define a function to pass the input thru the encoder and decoder in order to reconstruct the input
    return Decoder(Encoder(x,w),w)

num_steps = 1000
batch_size = 512
learning_rate = 1e-3

#necessary lib and modules for data handling, modeling and visualaztions
from scipy import stats
import numpy as np
import matplotlib.pyplot as plt
import urllib.request
from PIL import Image
from imageio import *
import torch
from skimage.transform import resize
from mpl_toolkits.axes_grid1.axes_rgb import make_rgb_axes, RGBAxes
from torchvision.models import *
from torchvision.datasets import MNIST,KMNIST,FashionMNIST
from skimage.util import montage

def randn_trunc(s): #Truncated Normal Random Numbers
    mu = 0 #mean 0
    sigma = 0.1 #standard deviation 0.1
    R = stats.truncnorm((-2*sigma - mu) / sigma, (2*sigma - mu) / sigma, loc=mu, scale=sigma)
    return R.rvs(s)

#Encode #initialize incoder weights
w0 = GPU(randn_trunc((64,1,4,4)))
w1 = GPU(randn_trunc((128,64,4,4)))
w2 = GPU(randn_trunc((10,6272)))
#Decode #initialize decoder weights
w3 = GPU(randn_trunc((6272,10)))
w4 = GPU(randn_trunc((128,64,4,4)))
w5 = GPU(randn_trunc((64,1,4,4)))

w = [w0,w1,w2,w3,w4,w5] #the list of weights combined

optimizer = torch.optim.Adam(params=w, lr=learning_rate)

for i in range(num_steps):

    x_real,y = get_batch('train') #real train data

    x_fake = Autoencoder(x_real,w) #reconstructed data

    loss = torch.mean((x_fake - x_real)**2) #loss between the real and reconstructed data

    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    if i % 100 == 0: print(loss.item())

image_batch,y = get_batch('test')

image_batch_recon = Autoencoder(image_batch,w) #to generate reconstructed images

torch.mean((image_batch_recon - image_batch)**2)

montage_plot(image_batch[0:25,0,:,:].cpu().detach().numpy()) #montage of the reconstructed images

montage_plot(image_batch_recon[0:25,0,:,:].cpu().detach().numpy())

"""
### Generator

"""



latent_size = 64 #sizes for the different layers of the neural network
hidden_size = 256
image_size = 784
b = 1024

#MNIST
# train_set = MNIST('./data', train=True, download=True)
# test_set = MNIST('./data', train=False, download=True)

#KMNIST
#train_set = KMNIST('./data', train=True, download=True)
#test_set = KMNIST('./data', train=False, download=True)

#Fashion MNIST
train_set = FashionMNIST('./data', train=True, download=True)
test_set = FashionMNIST('./data', train=False, download=True)

X = train_set.data.numpy() #convert dataset images and labels to numpy arrays
X_test = test_set.data.numpy()
Y = train_set.targets.numpy()
Y_test = test_set.targets.numpy()
X = X[:,None,:,:]/255 #normalize the image pixel values to the range [0,1]
X_test = X_test[:,None,:,:]/255
X = (X - 0.5)/0.5 #normalize the imageswith mean 0 and standard divation 1
X_test = (X_test - 0.5)/0.5

n = 7

index = np.where(Y == n)
X = X[index]
index = np.where(Y_test == n)
X_test = X_test[index]

X.shape,Y.shape,X_test.shape,Y_test.shape

###################################################

X = GPU_data(X)
X_test = GPU_data(X_test)
Y = GPU_data(Y)
Y_test = GPU_data(Y_test)

x,y = get_batch('train')



x.shape

montage_plot(x[0:25,0,:,:].detach().cpu().numpy())

#D #neural network weights with random truncated normal intialization and transfer to GPU
w0 = GPU(randn_trunc((64,1,4,4))) #first convolutional layer weights
w1 = GPU(randn_trunc((128,64,4,4))) #second
w2 = GPU(randn_trunc((1,6272)))# reshape- weights
#G
w3 = GPU(randn_trunc((6272,64))) #decoder weights to unflatten
w4 = GPU(randn_trunc((128,64,4,4))) #decoder convoluational layer weights
w5 = GPU(randn_trunc((64,1,4,4))) #final decoder convulational layer weights

w = [w0,w1,w2,w3,w4,w5]

def D(x,w):
    x = relu(conv2d(x,w[0], stride=(2, 2), padding=(1, 1)))
    x = relu(conv2d(x,w[1], stride=(2, 2), padding=(1, 1)))
    x = x.view(x.size(0), 6272) #to flattten the output
    x = linear(x,w[2]) # apply a linear layer
    x = torch.sigmoid(x)# apply sigmoid activation function
    return x

def G(x,w):# to generate image starting from the latent vector x using w
    x = linear(x,w[3])
    x = x.view(x.size(0), 128, 7, 7) #reshape for deconvoluation
    x = relu(conv_transpose2d(x,w[4], stride=(2, 2), padding=(1, 1)))
    x = torch.tanh(conv_transpose2d(x,w[5], stride=(2, 2), padding=(1, 1)))
    return x

b = 1024 #batch for training

batch_size = b

batch_size

d_optimizer = torch.optim.Adam(w[0:3], lr=0.0002) #initialize optimizer for discriminator
g_optimizer = torch.optim.Adam(w[3:], lr=0.0002) #initialize optimizer for generator

real_labels = (torch.ones(batch_size, 1).cuda()) #real data (labels)
fake_labels = (torch.zeros(batch_size, 1).cuda()) #fake data (labels)

num_epochs = 500 #compute number of batches and stpes for the train loop
batches = X.shape[0]//batch_size
steps = num_epochs*batches

#initialize latent vectors
z1 = (torch.randn(steps,batch_size,latent_size).cuda())
z2 = (torch.randn(steps,batch_size,latent_size).cuda())

for i in range(steps):

    images,y = get_batch('train') #batch of real images

    d_loss = binary_cross_entropy(D(images,w), real_labels) + binary_cross_entropy(D(G(z1[i],w),w), fake_labels) #loss for real and fake images
    d_optimizer.zero_grad() #reset gradients for the discriminator
    d_loss.backward() #back propagate the loss
    d_optimizer.step() #update discriminator weights


    g_loss = binary_cross_entropy(D(G(z2[i],w),w), real_labels) #compute loss for generator
    g_optimizer.zero_grad() #reset for generator
    g_loss.backward()
    g_optimizer.step() #update generator weights


    if i % 200 == 0:
        out = G(z1[np.random.randint(steps)],w)
        montage_plot(out.view(batch_size,1,28,28).detach().cpu().numpy()[0:25,0,:,:])





z1[np.random.randint(steps)].shape #random latent vector shape to verify tensor dim

noise = GPU_data(torch.randn(1,64)) #random latent vector, transfer to GPU

output = G(noise,w) #generate fake image

output.shape #print the shape of the output

plot(output[0,0]) #first example from the generated batch of outputs



















