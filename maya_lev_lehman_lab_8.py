# -*- coding: utf-8 -*-
"""Maya Lev Lehman Lab 8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WzJl_o1flPFRROGW6zdq7X-9c-J_4hqZ
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install wandb #install Weight and Bias library
# !apt-get install poppler-utils # install utilities for PDF files
# !pip install pdf2image # install library to convert PDF files to images
# !pip install flashtorch # install PyTorch-based visualizations
# 
# import requests #to make HTTP requests
# from pdf2image import convert_from_path # to convert PDF files to images
# import matplotlib.pyplot as plt #to generate plots
# import numpy as np #for numerical operations
# import torch #for tensor computations
# import requests
# from torchvision import * #for computer vision tasks
# from torchvision.models import * # pretained models in torchvision
# import wandb as wb  #weight and bias lib for experiment tracking

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu") #set 'device' to GPU if available, else set it to CPU

def GPU(data): #defining a function that moves data to GPU with gradient computation enabled
    return torch.tensor(data, requires_grad=True, dtype=torch.float, device=device)

def GPU_data(data): #defining a function that moves data to GPU without gradient computation enabled
    return torch.tensor(data, requires_grad=False, dtype=torch.float, device=device)

def plot(x): #defining a function to plot an image
    fig, ax = plt.subplots()
    im = ax.imshow(x, cmap = 'gray') #gray colormap
    ax.axis('off')
    fig.set_size_inches(5, 5)
    plt.show()

def get_google_slide(url): #defining a function that generates URL and exports a google slide as PDF
    url_head = "https://docs.google.com/presentation/d/"
    url_body = url.split('/')[5] #extract presentation ID from URL
    page_id = url.split('.')[-1] #extract page ID from URl
    return url_head + url_body + "/export/pdf?id=" + url_body + "&pageid=" + page_id #construct export URL for PDF

def get_slides(url): #defining a functon that will fetch slides from a google presentation and convert them to images
    url = get_google_slide(url)
    r = requests.get(url, allow_redirects=True) #fetch PDF file from URL
    open('file.pdf', 'wb').write(r.content) #save PDF file locally
    images = convert_from_path('file.pdf', 500) #convert PDF to images
    return images

def load(image, size=224): #defining a function that will load and preprocess an image for model input
    means = [0.485, 0.456, 0.406] #image normalization mean values
    stds = [0.229, 0.224, 0.225] #image normalization standard deviation values
    transform = transforms.Compose([ #image transformation pipeline
        transforms.Resize(size), # resize image to specified size
        transforms.CenterCrop(size), #center crop image to specified size
        transforms.ToTensor(), #convert the image to PyTorch tensor
        transforms.Normalize(means, stds)
    ])
    tensor = transform(image).unsqueeze(0).to(device)  #apply transformation, and move tensor to specified device
    tensor.requires_grad = True #enable gradient computation for tensor
    return tensor

#fetch labels from a predefined URL
labels = {int(key):value for (key, value) in requests.get('https://s3.amazonaws.com/mlpipes/pytorch-quick-start/labels.json').json().items()}

model = alexnet(weights='DEFAULT').to(device) #load the pretained AlexNet model and move to the specified device
model.eval(); #set model to evaluation mode

url = "https://docs.google.com/presentation/d/13a4KM3dNl8eSJ9v2lPkgfAc5LMut7LwC-bj2rlt4-Jg/edit?pli=1#slide=id.g2b78f4662ad_0_245" #google slides URL

images = [] #initialize list to store prepprocessed images

for image in get_slides(url): #iterate through each image fetched from the slides

    plot(image)

    images.append(load(image)) #load and preprocess the image and add it to the list

images = torch.vstack(images) #stack the preprocessed images into a single tensor

images.shape #shape of the preprocessed images tensor

model(images) #pass the preprocessed images tensor through the model to obtain predictions

y = model(images) #store model predictions



y.shape #check shape of the pred. tensor

guesses = torch.argmax(y, 1).cpu().numpy() #index of max value along 1 D

for i in list(guesses): #iterating thru the list of predicted indices
    print(labels[i]) #printing the labels using the 'fetched' labels dictionary

Y = np.zeros(50,) #numpy array of zeros (size is 50)
Y[25:] = 1 #set the values from index 25 onwards to 1

Y

Y = np.zeros(100,) #numpy array of zeros (size is 100)
Y[50:] = 1 #set the values from index 50 onwards to 1

Y

X = y.detach().cpu().numpy() #convert the predictions tensor to a numpy array and detach it from the computation graph

X.shape

plt.plot(X[0],'.') #plot the first row of the array

plt.hist(X[0]) #plot the histogram of the first row of the array

X = GPU_data(X) #move the array to GPU (without gradient computation enabled)
Y = GPU_data(Y) #move the modified array to GPU (without gradient computation enabled)

def softmax(x):
    s1 = torch.exp(x - torch.max(x,1)[0][:,None]) #x is the input tensor
    s = s1 / s1.sum(1)[:,None] # s is the output tensor after applying the softmax function
    return s

#cross-entropy loss function
def cross_entropy(outputs, labels):
    return -torch.sum(softmax(outputs).log()[range(outputs.size()[0]), labels.long()])/outputs.size()[0]
#computing the cross-entropy loss between predicted outputs and true labels

def randn_trunc(s): #Truncated Normal Random Numbers (or in short TN)
    mu = 0
    sigma = 0.1
    R = stats.truncnorm((-2*sigma - mu) / sigma, (2*sigma - mu) / sigma, loc=mu, scale=sigma)
    return R.rvs(s) #s is shape of the generated rand. numbers ##returns rand. numbers with shape 's' following the TN distribution

def Truncated_Normal(size): #Truncated Normal Random Numbers

    u1 = torch.rand(size)*(1-np.exp(-2)) + np.exp(-2)
    u2 = torch.rand(size)
    z  = torch.sqrt(-2*torch.log(u1)) * torch.cos(2*np.pi*u2)

    return z #returns numbers with shape 'size' following the TN distribution

def acc(out,y): #accuracy function
    with torch.no_grad():
        return (torch.sum(torch.max(out,1)[1] == y).item())/y.shape[0] #returns accuarcy value #y: True labels #out: predicted outputs from the model

X.shape #shape of the numpy array

def get_batch(mode): #batch of data
    b = c.b #batch size
    if mode == "train":
        r = np.random.randint(X.shape[0]-b) #rand. index for training batch
        x = X[r:r+b,:] #training batch input
        y = Y[r:r+b] #training batch output
    elif mode == "test":
        r = np.random.randint(X_test.shape[0]-b) #rand. index for test batch
        x = X_test[r:r+b,:] #test batch input
        y = Y_test[r:r+b] #test batch output
    return x,y

def model(x,w): #defining the linear model

    return x@w[0] #x: input data #w: model weights ##returns model predictions

def make_plots(): #make plots and log training accuracy

    acc_train = acc(model(x,w),y) #training accuracy

    xt,yt = get_batch('test')

    acc_test = acc(model(xt,w),yt) #test accuracy

    wb.log({"acc_train": acc_train}) #log training accuracy

wb.init(project="Linear_Model_Photo_1"); #initialize Weight and Bias project
c = wb.config #configuration object

c.h = 0.001  #learning rate
c.b = 32  #batch size
c.epochs = 100000  #number of epochs

w = [GPU(Truncated_Normal((1000,2)))]  #initialize weights with TN Random Numbers

optimizer = torch.optim.Adam(w, lr=c.h)

for i in range(c.epochs): #training loop

    x,y = get_batch('train') #get training batch

    loss = cross_entropy(softmax(model(x,w)),y) #calculate loss

    optimizer.zero_grad()
    loss.backward() #backpropagation
    optimizer.step()

    wb.log({"loss": loss}) #log loss

    make_plots() #make plots and log accuracy





















